# pakfro-ext README

This is a dry run of creating a vscode extension in Node.js and basic webdev stack that leverages a locally running llm, in this case "llama3.1:8b" (Llama 3.1 8 billion parameter by Meta)

I used a boilerplate from Yeoman and generator-code (npm
)
## Features

- Launches a debug window with the extension running
- calling the command runs the extension
- basic HTML/CSS/JS for prompt input and response from LLM


## Requirements
##### TODO: ADD LINKS

- Node.js
- Locally running LLM
- ollama 